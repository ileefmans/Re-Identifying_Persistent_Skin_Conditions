{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/Insight/Project/Re-Identifying_Persistent_Skin_Conditions/skinConditionDetect\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ianleefmans/Desktop/Insight/Project/Re-Identifying_Persistent_Skin_Conditions/skinConditionDetect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using custom datahelper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "#from datahelper import CreateDataset\n",
    "from datahelper2 import CreateDataset, my_collate2\n",
    "from facealign import FaceAlign, CalculateMatches\n",
    "from run_match import GeoMatch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision\n",
    "#from model import STN\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import imutils\n",
    "import argparse\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paths\n",
    "pickle_path2 = \"/Users/ianleefmans/Desktop/Insight/Project/Re-Identifying_Persistent_Skin_Conditions/skinConditionDetect/pickle/simple_train_dict.pkl\"\n",
    "pickle_path = \"/Users/ianleefmans/Desktop/Insight/Project/Re-Identifying_Persistent_Skin_Conditions/skinConditionDetect/pickle/train_annotation_dict.pkl\"\n",
    "data_directory = \"/Users/ianleefmans/Desktop/Insight/Project/Data\"\n",
    "\n",
    "# Create dataset\n",
    "dataset = CreateDataset(pickle_path2, data_directory, local=True, geometric=False, transform = torchvision.transforms.ToTensor())\n",
    "def my_collate3(batch):\n",
    "    image0 = [item[0] for item in batch]\n",
    "    image1 = [item[1] for item in batch]\n",
    "    annotation0 = [item[2] for item in batch]\n",
    "    annotation1 = [item[3] for item in batch]\n",
    "    #target = torch.LongTensor(target)\n",
    "    return image0, image1, annotation0, annotation1\n",
    "\n",
    "def my_collate(batch):\n",
    "    image = [item[0] for item in batch]\n",
    "    image = torch.stack(image)\n",
    "    annotation = [item[1] for item in batch]\n",
    "    #target = torch.LongTensor(target)\n",
    "    return image, annotation\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=2, num_workers=0, shuffle=True, collate_fn=my_collate2)\n",
    "sample = iter(train_loader).next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = 'shape_predictor_68_face_landmarks.dat'\n",
    "sample1 = (sample[0], sample[2])\n",
    "sample2 = (sample[1], sample[3])\n",
    "fa1 = FaceAlign(sample1, predictor)\n",
    "fa2 = FaceAlign(sample2, predictor)\n",
    "\n",
    "image1, boxes1 = fa1.forward()\n",
    "image2, boxes2 = fa2.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1_list = []\n",
    "matched_boxes = {}\n",
    "for i in range(len(boxes1)):\n",
    "    for j in range(len(boxes2)):\n",
    "        ca = CalculateMatches(image1, image2, boxes1[i], boxes2[j])\n",
    "        IoU = ca.evaluate()\n",
    "        if IoU>0:\n",
    "            if i in box1_list:\n",
    "                if IoU > matched_boxes[i][0]:\n",
    "                    matched_boxes[i] = (IoU, j)\n",
    "            else:\n",
    "                matched_boxes[i] = (IoU, j)\n",
    "                box1_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: (0.46981529688855833, 0), 11: (0.743939263221465, 1)}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IANet (testing forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import STN, Encoder, IANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 256, 256]) torch.Size([4, 20, 61, 61])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,3, 256, 256)\n",
    "\n",
    "ian_net = IANet()\n",
    "y, z = ian_net(x)\n",
    "\n",
    "print(y.size(), z.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace for working with annotation jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:04<00:00, 10.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis =[]\n",
    "for i in tqdm(range(31085, 31130)):\n",
    "    try:\n",
    "        dataset[i]\n",
    "    except:\n",
    "        lis.append(i)\n",
    "        print(i)\n",
    "    finally:\n",
    "        pass\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232333"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sample[0]\n",
    "annotation = sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = \"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\"\n",
    "\n",
    "test_json = 'user_000000000000.json'\n",
    "\n",
    "df = pd.read_json(data_path+test_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cam2_c1b091a30a5f09b1_abfafa_front_280519_1731196.jpg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3].image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face_detected': True,\n",
       " 'facebox': None,\n",
       " 'landmarks': {'UPPER_LIP': {'x': 483, 'y': 1004, 'z': -49.52797317504883},\n",
       "  'RIGHT_EYE_RIGHT_CORNER': {'x': 866, 'y': 671, 'z': -59.51887893676758},\n",
       "  'LEFT_EYE_BOTTOM_BOUNDARY': {'x': 416, 'y': 641, 'z': 1.275591969490051},\n",
       "  'LEFT_OF_LEFT_EYEBROW': {'x': 326, 'y': 486, 'z': 30.097854614257812},\n",
       "  'CHIN_RIGHT_GONION': {'x': 1033, 'y': 1128, 'z': 25.548309326171875},\n",
       "  'RIGHT_EYE_LEFT_CORNER': {'x': 703, 'y': 649, 'z': -46.64808654785156},\n",
       "  'CHIN_GNATHION': {'x': 480, 'y': 1282, 'z': -14.199127197265625},\n",
       "  'NOSE_TIP': {'x': 446, 'y': 862, 'z': -84.45030212402344},\n",
       "  'RIGHT_EYE_BOTTOM_BOUNDARY': {'x': 776, 'y': 684, 'z': -59.52267074584961},\n",
       "  'RIGHT_OF_RIGHT_EYEBROW': {'x': 926, 'y': 607, 'z': -69.99092102050781},\n",
       "  'MOUTH_CENTER': {'x': 489, 'y': 1048, 'z': -38.64469909667969},\n",
       "  'RIGHT_EYE_PUPIL': {'x': 763, 'y': 667, 'z': -62.7679557800293},\n",
       "  'FOREHEAD_GLABELLA': {'x': 559, 'y': 538, 'z': -60.88658905029297},\n",
       "  'LEFT_EYE_PUPIL': {'x': 404, 'y': 601, 'z': -0.781676352024078},\n",
       "  'LEFT_EYE_TOP_BOUNDARY': {'x': 406, 'y': 575, 'z': -7.699437618255615},\n",
       "  'NOSE_BOTTOM_CENTER': {'x': 488, 'y': 929, 'z': -52.74549102783203},\n",
       "  'CHIN_LEFT_GONION': {'x': 315, 'y': 999, 'z': 149.53884887695312},\n",
       "  'RIGHT_EYEBROW_UPPER_MIDPOINT': {'x': 776,\n",
       "   'y': 531,\n",
       "   'z': -80.76531219482422},\n",
       "  'LEFT_EYEBROW_UPPER_MIDPOINT': {'x': 397,\n",
       "   'y': 459,\n",
       "   'z': -15.414263725280762},\n",
       "  'MOUTH_LEFT': {'x': 402, 'y': 1028, 'z': 7.819148063659668},\n",
       "  'RIGHT_EAR_TRAGION': {'x': 1179, 'y': 879, 'z': 60.3297004699707},\n",
       "  'LEFT_EYE_LEFT_CORNER': {'x': 361, 'y': 589, 'z': 25.002363204956055},\n",
       "  'RIGHT_EYE': {'x': 780, 'y': 654, 'z': -60.88290023803711},\n",
       "  'RIGHT_EYE_TOP_BOUNDARY': {'x': 756, 'y': 640, 'z': -68.00523376464844},\n",
       "  'LOWER_LIP': {'x': 485, 'y': 1111, 'z': -36.89296340942383},\n",
       "  'NOSE_BOTTOM_RIGHT': {'x': 616, 'y': 906, 'z': -51.12159729003906},\n",
       "  'RIGHT_OF_LEFT_EYEBROW': {'x': 481, 'y': 527, 'z': -41.36788558959961},\n",
       "  'MIDPOINT_BETWEEN_EYES': {'x': 544, 'y': 601, 'z': -55.99053192138672},\n",
       "  'LEFT_EYE_RIGHT_CORNER': {'x': 493, 'y': 624, 'z': -10.477961540222168},\n",
       "  'MOUTH_RIGHT': {'x': 659, 'y': 1081, 'z': -38.54375457763672},\n",
       "  'LEFT_EAR_TRAGION': {'x': 384, 'y': 738, 'z': 198.24478149414062},\n",
       "  'NOSE_BOTTOM_LEFT': {'x': 429, 'y': 867, 'z': -17.06230354309082},\n",
       "  'LEFT_OF_RIGHT_EYEBROW': {'x': 652, 'y': 558, 'z': -70.57413482666016},\n",
       "  'LEFT_EYE': {'x': 426, 'y': 613, 'z': -0.00038296135608100005}},\n",
       " 'pan_angle': -26.176912307739258,\n",
       " 'roll_angle': 7.954537868499756,\n",
       " 'tilt_angle': -5.522506237030029,\n",
       " 'image_height': 1440,\n",
       " 'image_width': 1440,\n",
       " 'annotation': [{'bounding_boxes': [],\n",
       "   'bounding_boxes_actual': [],\n",
       "   'condition': 'Not Detected',\n",
       "   'label': 'pimple-region',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'bounding_boxes': ['1000,766,1037,806',\n",
       "    '516,441,556,482',\n",
       "    '954,774,990,810',\n",
       "    '618,1197,658,1234',\n",
       "    '744,823,780,860',\n",
       "    '757,888,798,928',\n",
       "    '952,749,985,785',\n",
       "    '651,311,691,351',\n",
       "    '948,798,984,834',\n",
       "    '782,729,818,766'],\n",
       "   'bounding_boxes_actual': ['1009,776,1028,796',\n",
       "    '526,451,546,472',\n",
       "    '963,783,981,801',\n",
       "    '628,1206,648,1225',\n",
       "    '753,832,771,851',\n",
       "    '767,898,788,918',\n",
       "    '960,758,977,776',\n",
       "    '661,321,681,341',\n",
       "    '957,807,975,825',\n",
       "    '791,738,809,757'],\n",
       "   'condition': 'Detected',\n",
       "   'label': 'come-region',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'bounding_boxes': ['888,992,937,1048', '759,864,804,908'],\n",
       "   'bounding_boxes_actual': ['900,1006,925,1034', '770,875,793,897'],\n",
       "   'condition': 'Detected',\n",
       "   'label': 'darkspot-region',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'polygon_point_sequence': [],\n",
       "   'polygon_point_sequence_actual': None,\n",
       "   'condition': 'Not Detected',\n",
       "   'label': 'DarkCircle',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'bounding_boxes': ['969,718,1013,762', '787,838,836,878'],\n",
       "   'bounding_boxes_actual': ['980,729,1002,751', '799,848,824,868'],\n",
       "   'condition': 'Detected',\n",
       "   'label': 'ascar-region',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'bounding_boxes': ['903,948,996,1040'],\n",
       "   'bounding_boxes_actual': ['926,971,973,1017'],\n",
       "   'condition': 'Detected',\n",
       "   'label': 'oscar-region',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'polygon_point_sequence': [],\n",
       "   'polygon_point_sequence_actual': None,\n",
       "   'condition': 'Not Detected',\n",
       "   'label': 'PuffyEyes',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'polygon_point_sequence': [],\n",
       "   'polygon_point_sequence_actual': None,\n",
       "   'condition': 'Not Detected',\n",
       "   'label': 'PerioralPigmentation',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'polygon_point_sequence': [],\n",
       "   'polygon_point_sequence_actual': None,\n",
       "   'condition': 'Not Detected',\n",
       "   'label': 'OpenPores',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None},\n",
       "  {'polygon_point_sequence': [],\n",
       "   'polygon_point_sequence_actual': None,\n",
       "   'condition': 'Not Detected',\n",
       "   'label': 'Melasma',\n",
       "   'confidence': None,\n",
       "   'confidences_actual': None,\n",
       "   'threshold': None}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].image_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if any pictures are repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17293/17293 [04:06<00:00, 70.24it/s]\n"
     ]
    }
   ],
   "source": [
    "repeated_pics = []\n",
    "for filename in tqdm(os.listdir(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\")):\n",
    "    df = pd.read_json(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\"+filename)\n",
    "    if \"image_path\" in df.columns:\n",
    "        if df.image_path.nunique()==len(df)-df.image_path.isna().sum():\n",
    "            pass\n",
    "        else:\n",
    "            vc = df.image_path.value_counts()\n",
    "            repeated_pic+=list(vc[vc>1].index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repeated_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary Mapping Index to Entry in Json File  \n",
    "- save to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17293/17293 [07:27<00:00, 38.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "annotation_dict = {}\n",
    "count = 0 \n",
    "tot_count=0\n",
    "for filename in tqdm(os.listdir(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\")):\n",
    "    try:\n",
    "        df = pd.read_json(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\"+filename)\n",
    "        df = df.loc[(df.image_details.notnull()) & (df.image_path.notnull()),:]\n",
    "        for i in list(df.index.values):\n",
    "            try:\n",
    "                df.iloc[i].image_details['annotation'] !=None\n",
    "                df.iloc[i]['image_details']['annotation'][0]\n",
    "                ok = False\n",
    "                for j in df.iloc[i].image_details['annotation']:\n",
    "                    if (j['condition']=='Detected') and ('bounding_boxes' in j.keys()):\n",
    "                        if len(j['bounding_boxes'])>0:\n",
    "                            ok = True\n",
    "                if ok ==False:\n",
    "                    a = 2/0\n",
    "                    \n",
    "                annotation_dict[count] = (filename, i)\n",
    "                \n",
    "                count+=1\n",
    "                \n",
    "                    \n",
    "            except:\n",
    "                print\n",
    "            finally:\n",
    "                pass\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        pass\n",
    "with open(\"annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(annotation_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickle\n",
    "with open(\"pickle/annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)\n",
    "# open list of bad json entries\n",
    "with open(\"pickle/bad_json_entry.pkl\", 'rb') as handle:\n",
    "    bad_json = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad json entries form dictionary\n",
    "for i in bad_json:\n",
    "    dictionary.pop(i)\n",
    "\n",
    "newdictionary = {}\n",
    "count= 0\n",
    "for i in dictionary:\n",
    "    newdictionary[count]=dictionary[i]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-pickle dictionary\n",
    "with open(\"annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(newdictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) # dictionary length after removing 467 bad json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) # dictionary length after removing 11 bad json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232811"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) # dictionary length before removing 11 bad json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train, Val, and Test splits on Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232333/232333 [00:00<00:00, 517815.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dictionary = {}\n",
    "val_dictionary = {}\n",
    "test_dictionary = {}\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in tqdm(dictionary):\n",
    "    if i<162632:\n",
    "        train_dictionary[i] = dictionary[i]\n",
    "    elif i<197483:\n",
    "        val_dictionary[count1] = dictionary[i]\n",
    "        count1+=1\n",
    "    else:\n",
    "        test_dictionary[count2] = dictionary[i]\n",
    "        count2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle train dictionary\n",
    "with open(\"train_annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(train_dictionary, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle val_dictionary\n",
    "with open(\"val_annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(val_dictionary, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle test_dictionary\n",
    "with open(\"test_annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(test_dictionary, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of image and annotation pairs (for train test and val splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/train_annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "simple_train_dict = {}\n",
    "for i in dictionary:\n",
    "    if i!=0:\n",
    "        if dictionary[i][0]==dictionary[i-1][0]:\n",
    "            simple_train_dict[count] = (dictionary[i-1], dictionary[i])\n",
    "            count+=1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/simple_train_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(simple_train_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/val_annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "simple_val_dict = {}\n",
    "for i in dictionary:\n",
    "    if i!=0:\n",
    "        if dictionary[i][0]==dictionary[i-1][0]:\n",
    "            simple_val_dict[count] = (dictionary[i-1], dictionary[i])\n",
    "            count+=1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/simple_val_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(simple_val_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/test_annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "simple_test_dict = {}\n",
    "for i in dictionary:\n",
    "    if i!=0:\n",
    "        if dictionary[i][0]==dictionary[i-1][0]:\n",
    "            simple_test_dict[count] = (dictionary[i-1], dictionary[i])\n",
    "            count+=1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/simple_test_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(simple_test_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/simple_train_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
