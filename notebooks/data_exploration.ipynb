{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/Insight/Project/Re-Identifying_Persistent_Skin_Conditions/skinConditionDetect\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ianleefmans/Desktop/Insight/Project/Re-Identifying_Persistent_Skin_Conditions/skinConditionDetect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using custom datahelper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "from datahelper import CreateDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision\n",
    "from model import MVP\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import imutils\n",
    "import argparse\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paths\n",
    "pickle_path = \"/Users/ianleefmans/Desktop/Insight/Project/Re-Identifying_Persistent_Skin_Conditions/skinConditionDetect/annotation_dict.pkl\"\n",
    "data_directory = \"/Users/ianleefmans/Desktop/Insight/Project/Data\"\n",
    "\n",
    "# Create dataset\n",
    "dataset = CreateDataset(pickle_path, data_directory, local=True, geometric=True, transform = torchvision.transforms.ToTensor())\n",
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    #target = torch.LongTensor(target)\n",
    "    return data, target\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=1, num_workers=0, shuffle=True, collate_fn=my_collate)\n",
    "sample = iter(train_loader).next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace for working with annotation jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:04<00:00, 10.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis =[]\n",
    "for i in tqdm(range(31085, 31130)):\n",
    "    try:\n",
    "        dataset[i]\n",
    "    except:\n",
    "        lis.append(i)\n",
    "        print(i)\n",
    "    finally:\n",
    "        pass\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232333"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sample[0]\n",
    "annotation = sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = \"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\"\n",
    "\n",
    "test_json = 'user_000000000000.json'\n",
    "\n",
    "df = pd.read_json(data_path+test_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cam2_c1b091a30a5f09b1_abfafa_front_280519_1718016.jpg'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if any pictures are repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17293/17293 [04:06<00:00, 70.24it/s]\n"
     ]
    }
   ],
   "source": [
    "repeated_pics = []\n",
    "for filename in tqdm(os.listdir(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\")):\n",
    "    df = pd.read_json(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\"+filename)\n",
    "    if \"image_path\" in df.columns:\n",
    "        if df.image_path.nunique()==len(df)-df.image_path.isna().sum():\n",
    "            pass\n",
    "        else:\n",
    "            vc = df.image_path.value_counts()\n",
    "            repeated_pic+=list(vc[vc>1].index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repeated_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary Mapping Index to Entry in Json File  \n",
    "- save to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17293/17293 [07:27<00:00, 38.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "annotation_dict = {}\n",
    "count = 0 \n",
    "tot_count=0\n",
    "for filename in tqdm(os.listdir(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\")):\n",
    "    try:\n",
    "        df = pd.read_json(\"/Users/ianleefmans/Desktop/Insight/Project/Data/followup_data/\"+filename)\n",
    "        df = df.loc[(df.image_details.notnull()) & (df.image_path.notnull()),:]\n",
    "        for i in list(df.index.values):\n",
    "            try:\n",
    "                df.iloc[i].image_details['annotation'] !=None\n",
    "                df.iloc[i]['image_details']['annotation'][0]\n",
    "                ok = False\n",
    "                for j in df.iloc[i].image_details['annotation']:\n",
    "                    if (j['condition']=='Detected') and ('bounding_boxes' in j.keys()):\n",
    "                        if len(j['bounding_boxes'])>0:\n",
    "                            ok = True\n",
    "                if ok ==False:\n",
    "                    a = 2/0\n",
    "                    \n",
    "                annotation_dict[count] = (filename, i)\n",
    "                \n",
    "                count+=1\n",
    "                \n",
    "                    \n",
    "            except:\n",
    "                print\n",
    "            finally:\n",
    "                pass\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        pass\n",
    "with open(\"annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(annotation_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickle\n",
    "with open(\"pickle/annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)\n",
    "# open list of bad json entries\n",
    "with open(\"pickle/bad_json_entry.pkl\", 'rb') as handle:\n",
    "    bad_json = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad json entries form dictionary\n",
    "for i in bad_json:\n",
    "    dictionary.pop(i)\n",
    "\n",
    "newdictionary = {}\n",
    "count= 0\n",
    "for i in dictionary:\n",
    "    newdictionary[count]=dictionary[i]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-pickle dictionary\n",
    "with open(\"annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(newdictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) # dictionary length after removing 467 bad json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) # dictionary length after removing 11 bad json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232811"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) # dictionary length before removing 11 bad json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train, Val, and Test splits on Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232333/232333 [00:00<00:00, 517815.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dictionary = {}\n",
    "val_dictionary = {}\n",
    "test_dictionary = {}\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in tqdm(dictionary):\n",
    "    if i<162632:\n",
    "        train_dictionary[i] = dictionary[i]\n",
    "    elif i<197483:\n",
    "        val_dictionary[count1] = dictionary[i]\n",
    "        count1+=1\n",
    "    else:\n",
    "        test_dictionary[count2] = dictionary[i]\n",
    "        count2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle train dictionary\n",
    "with open(\"train_annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(train_dictionary, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle val_dictionary\n",
    "with open(\"val_annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(val_dictionary, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle test_dictionary\n",
    "with open(\"test_annotation_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(test_dictionary, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of image and annotation pairs (for train test and val splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/train_annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "simple_train_dict = {}\n",
    "for i in dictionary:\n",
    "    if i!=0:\n",
    "        if dictionary[i][0]==dictionary[i-1][0]:\n",
    "            simple_train_dict[count] = (dictionary[i-1], dictionary[i])\n",
    "            count+=1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/simple_train_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(simple_train_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/val_annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "simple_val_dict = {}\n",
    "for i in dictionary:\n",
    "    if i!=0:\n",
    "        if dictionary[i][0]==dictionary[i-1][0]:\n",
    "            simple_val_dict[count] = (dictionary[i-1], dictionary[i])\n",
    "            count+=1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/simple_val_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(simple_val_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/test_annotation_dict.pkl\", 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "simple_test_dict = {}\n",
    "for i in dictionary:\n",
    "    if i!=0:\n",
    "        if dictionary[i][0]==dictionary[i-1][0]:\n",
    "            simple_test_dict[count] = (dictionary[i-1], dictionary[i])\n",
    "            count+=1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/simple_test_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(simple_test_dict, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
